<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[西瓜书笔记1--决策树算法]]></title>
    <url>%2F2018%2F10%2F18%2F%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[决策树构建基本流程 划分属性选择 剪枝处理 连续与缺失值处理 分类决策树分类决策树的结构主要包括：根节点，分支，非叶子节点和叶子节点。分支代表按照对应属性的划分行为，非叶子节点表示指示划分的条件，代表按照哪个属性对数据进行划分，叶子节点表示分类后所得的分类标签。 1.决策树构建基本流程决策树的构建过程是一个递归过程，首先按照某种规则依次选属性，当选择了一个属性作为划分属性后，分支对应了属性的各个离散值，在以下情形下会产生叶子节点，即递归返回： 当前节点包含的样本全部属于同一类别 当前属性集为空 当前节点包含的所有样本在所有属性上取值相同 —-类别标记为该节点所含样本最多的类别 当前节点包含的样本集合为空 —-类别标记为其父节点所含样本最多的类别 2.划分属性选择算法划分属性选择的算法包括： 信息增益（ID3） 增益率 （C4.5） 基尼指数 (CART) 随着划分的进行，我们希望决策树的分支节点所包含的样本尽可能属于同一类别，即节点的纯度越来越高。 信息增益信息熵是度量样本集合纯度的一种常用指标，假定当前样本集合$D$中第$k$类样本所占的比例为$p_k$($k = 1,2,…,|y|)$,则$D$的信息熵定义为 Ent(D) = -\sum_{k=1}^{|y|}p_k\log_2p_k$Ent(D)$的值越小，则$D$的纯度就越高。 信息增益衡量了使用属性$a$来划分数据时所获得的纯度提升。 \begin{align} Gain(D,a) &= \sum_{v=1}^{V}\frac{|D^v|}{|D|}Pure(D^v)-Pure(D)\\ &=Ent(D)- \sum_{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v) \end{align}因此最优的划分属性$a$为$a^* = \arg\max_{a\in A}Gain(D,a)$ 增益率信息增益准则对可取数目较多的属性有所偏好，例如若加入“编号”属性，信息增益会很大，因为每个分支的纯度都已达到最大，但不具备泛化能力。为减少这种不利影响，采用增益率来选择最优划分属性。 属性$a$的固有值定义为 IV(a) = -\sum_{v=1}^V\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}属性$a$可能的取值数目越多，$IV(a)$的值会越大 增益率定义为 Gain\_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}增益率准则对可取值数目较少的属性有所偏好，C4.5算法采用启发式，先从候选划分属性中找出信息增益率高于平均水平的属性，再从中选择增益率最高的。 基尼指数基尼值是另一种度量数据集纯度的方式。 Gini(D)= \sum_{k=1}^{|y|}\sum_{k'\neq k}p_kp_{k'}=1-\sum_{k=1}^{|y|}p_k^2基尼值反映了从数据集$D$中随机抽取两个样本，其类别标记不一致的概率。$Gini(D)$越小，$D$的纯度越高。属性$a$的基尼指数定义为 Gini\_index(D,a) = \sum_{v=1}^{V}\frac{|D^v|}{|D|}Gini(D^v)因此最优的划分属性$a$为$a^* = \arg\min_{a\in A}Gini_index(D,a)$ 3.剪枝处理剪枝是决策树学习算法中避免过拟合的手段。 泛化性能由模型在验证集里的预测精度衡量。 预剪枝会面临欠拟合的风险，后剪枝的性能更好，但计算上的开销更大。 4.连续值与缺失值连续值采用二分法对连续属性进行处理。根据属性$a$中出现的所有可能取值，获得候选划分点集合$T_a$,在其中选择最合适的划分点$t$,将数据集$D$分为子集${D_t}^-$和${D_t}^+$两部分。 需要注意的是，连续属性在决策树中可以多次作为划分属性，每次需要重新选择合适的划分点。 缺失值 如何在属性值缺失的情况下进行划分属性选择？ 重新定义属性值缺失情况下信息增益的计算公式 $\tilde{D}$：$D$中在属性$a$上没有缺失值的样本子集 $\tilde{D}^v$: $\tilde{D}$中在属性$a$上取值为$a^v$的样本子集 $\tilde{D}_k$: $\tilde{D}$中属于第$k$类的样本子集 假定为每个样本$x$赋予一个权重$\omega_x$,定义以下比例项： 给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分？ 若样本$x$在划分属性$a$的取值已知，则将$x$划入与其取值对应的子节点，且样本权重在子节点中保持$\omega_x$;若样本$x$在划分属性$a$上的取值未知，则将$x$同时划入所有子节点，且样本权重在属性$a^v$对应的子节点中调整为$\tilde{r}_v\omega_x$,即直观来说就是把同一个样本以不同的概率划入到不同的子节点中去。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>西瓜书</tag>
        <tag>机器学习算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231课程笔记3--损失函数与优化]]></title>
    <url>%2F2018%2F10%2F16%2FCS231%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%89%2F</url>
    <content type="text"><![CDATA[损失函数和参数优化 支持向量机 损失函数损失函数是用来定量地描述分类模型的效果并以此选择最优的权重矩阵W的函数。给定数据集${(x_i,y_i)}$,在数据分类问题中即为图像数据及对应的标签，我们可以通过调整权重矩阵，是的评分函数的结果与训练数据集中图片的真实标签一致，即评分函数在正确的分类的位置应当得到最高的评分（score）。 损失函数的表达形式为 L = \frac{1}{N}\sum_iL_i(f(x_i,W),y_i)多类别SVM损失函数第i个数据中包含图像$x_i$的像素和代表正确类别的标签$y_i$。评分函数输入像素数据，然后通过公式$f(x_i,W)$来计算不同分类类别的分值。这里我们将分值简写为$s$。比如，针对第j个类别的得分就是第j个元素：$s_j = f(x_i,W)_j$。针对第i个数据的多类SVM的损失函数定义如下： L_i = \sum_{j\neq y_i}max(0,s_j-s_{y_i}+\Delta)SVM的损失函数想要正确分类类别$y_i​$的分数比不正确类别分数高，而且至少要高$\Delta​$。如果不满足这点，就开始计算损失值。$\Delta​$可以取值为1。$\max(0,)​$函数，它常被称为折叶损失（hinge loss）。总的损失函数为： L = \frac{1}{N}\sum_iL_i平方折叶损失SVM（即L2-SVM），它使用的是$\max(0,)^2$，将更强烈（平方地而不是线性地）地惩罚过界的边界值。不使用平方是更标准的版本，但是在某些数据集中，平方折叶损失会工作得更好。可以通过交叉验证来决定到底使用哪个。 损失函数正则化在训练模型的过程中，要防止模型的过拟合，通常的解决方式是加入正则项。在这里为损失函数添加一个附加的项。这是要分类器除了需要拟合训练集之外，同时鼓励模型以某种方式来选择更简单的W，这里的简单取决于任务的规模和使用的模型。假设正则项惩罚（记为R），这样标准损失函数现在就有两项，一个是损失值项和正则化项。这里有一个超参数$\lambda$用来平衡这两个项。 常见的正则项：]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CS231</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231课程笔记2--图像分类]]></title>
    <url>%2F2018%2F10%2F13%2FCS231%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[图像分类基础算法 K近邻算法，线性分类器 图像分类：计算机视觉的核心所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像。 困难和挑战：对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。计算机呈现图片的方式是一堆像素点（如800*600），每个像素点有红黄蓝三个维度的数据，图像是以3维数组来表示的，数组中的元素是亮度值。 计算机视觉算法在图像识别方面遇到的困难包括 语义鸿沟（Semantic gap）：很难从巨大的像素值数组中提取出图像的语义标签 视角变化 （Viewpoint variation）：当摄像机角度变化时像素值会发生巨大变化 光照条件（Illumination conditions） 形变（Deformation） 遮挡（Occlusion） 背景干扰（Background clutter） 类内差异（Intra-class variation）：同种物体年龄外表上有很大不同 面对以上所有变化及其组合，好的图像分类模型能够在面对上述挑战和干扰时具有很好的鲁棒性。 图像分类方法我们希望分类算法不是只适用于某个特定的种类，而是能够对所有种类的物体进行分类识别。 数据驱动的方法： 输入：输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为训练集 学习：使用输入的数据集训练分类器 评价：让分类器来预测新的图像的分类标签，并以此来评价分类器的质量 1. 最近邻算法（Nearest Neighbor分类器）训练：记录所有的数据和标签 预测：返回与输入图片最相近的样本数据的标签 在现实使用过程中，我们希望分类器的训练过程更长，而测试过程很快，但最近邻算法由于需要将测试图片与训练集里的所有样本进行比较，测试时间会很长，且预测效果不好。 2. K-近邻算法（K-Nearest Neighbors)在最近邻算法基础上做出一些改进，不只是寻找最近的1个点，而是找到最近的K个点，在这些点中进行投票，得到测试图片的标签。k值更大时，可以让分类的效果更平滑，使得分类器对于噪声更具有鲁棒性。 衡量两个图片的相似性方法，最简单的是计算两张图片像素矩阵的L1距离（曼哈顿距离）：$d_1(I_1,I_2)=\sum_P|I_1^P-I_2^p|$ L2距离（欧氏距离）：$d_2(I_1,I_2) = \sqrt{\sum_p(I_1^P-I_2^p)^2}$ 比较：L1距离取决于坐标系统的选择，当转动坐标轴时L1距离会发生变化，但L2距离不会。如果输入的特征向量对任务有重要的意义，则L1更合适，如果向量没有明确的含义，L2距离更加自然。 超参数:k的取值和距离的衡量方式选择都是超参数，超参数是无法在学习过程中得到的，而是要我们要给模型设置的。超参数的设置是依赖问题和数据的，所以一般要尝试不同的可能取值来检测哪种超参数的表现更好。 在设置超参数的过程中，不能在训练集或者测试集上寻找表现最好的超参数，而是应该将数据分为训练集，验证集和测试集，在训练集上运用不同的超参数来训练模型，在验证集上评估模型的效果，选择在验证集上效果最好的一组超参，再将这个模型运用在测试集上。对于小规模的数据集，还可以采用交叉验证方法：将测试集以外的数据分成K份，在其中（K-1)份上训练模型，在第K份数据上检验效果。 KNN算法在图像分类的问题中不会被用到，因为在预测数据时运算时间很长，L1和L2这种向量距离用在图像比较上不太合适，无法表示图像之间视觉感知的差异。另一个问题是维度灾难，KNN算法需要用训练数据将样本空间分成几个小的部分，若需要达到好的效果要求样本能够密集地分布在样本空间中，那么在高维数据中训练数据的数量就要是指数倍的增加，这是很难实现的。 3. 线性分类器线性分类方法是一种参数模型，通过训练数据学习出一组参数W用于预测新的样本，而非像KNN方法一样需要存储全部的训练数据，提高了测试的效率。在参数模型中，我们会获得一个包含输入数据x和参数W的函数$f(x,W)$,得到十个数字表示10个类别对应的分数。线性分类器中$f(x,W) = Wx+b$,b是偏差项，不与数据交互，只提供每个类别的偏好值。 线性分类模型可以理解为一种模板匹配方法，W矩阵中的每一行相当于每个图像类别学习出的模板。通过输入数据与模板的成绩得到图像的像素点与模板之间的相似之处，而偏差项给出了每个类的偏离量。因此线性分类器有每个类别只学习一个模板的限制。 线性分类器还可以在高维空间的角度来理解，每张图片代表着一个高维空间中的点，线性模型试图通过画出平面对不同类别的图像进行分割。 但线性模型的缺点是有很多形式的数据不能用线性平面进行分割。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CS231</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231课程笔记1--Introduction]]></title>
    <url>%2F2018%2F10%2F13%2FCS231%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[计算机视觉历史进展 CNN算法发展 计算机视觉历史进展目标分割：把一张图片的像素点归到有意义的区域 面部检测：使用Adaboost进行实时面部检测 目标检测：STFT特征，通过观察目标的某些部分和特征在变化中具有的表现性和不变性。所以目标识别的首要任务就是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配， 识别整幅图的场景：金字塔匹配：这个算法从图片的各个部分各像素抽取特征并把他们放在一起作为一个特征描述，然后使用特征描述跑SVM模型。 目标识别：标注数据集PASCAL Visual Object Challenge，Imagenet Imagenet竞赛中2012年CNN卷积神经网络模型取得了巨大的进步 CNN算法发展CNN算法在90年代被发明，但直到近几年才流行起来的原因 1.计算机运算能力的提升，GPU并行运算 2.数据集的完善，为训练网络提供了条件]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CS231</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这是我的第一篇博客]]></title>
    <url>%2F2018%2F10%2F12%2F%E6%96%B0%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[嘻嘻~这就是我的博客小窝啦]]></content>
      <tags>
        <tag>介绍</tag>
      </tags>
  </entry>
</search>
