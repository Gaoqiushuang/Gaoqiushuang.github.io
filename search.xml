<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CS231课程笔记二--图像分类]]></title>
    <url>%2F2018%2F10%2F13%2FCS231%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[K近邻算法，线性分类器，两层神经网络，图像特征 图像分类：计算机视觉的核心所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像。 困难和挑战：对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。计算机呈现图片的方式是一堆像素点（如800*600），每个像素点有红黄蓝三个维度的数据，图像是以3维数组来表示的，数组中的元素是亮度值。 计算机视觉算法在图像识别方面遇到的困难包括 语义鸿沟（Semantic gap）：很难从巨大的像素值数组中提取出图像的语义标签 视角变化 （Viewpoint variation）：当摄像机角度变化时像素值会发生巨大变化 光照条件（Illumination conditions） 形变（Deformation） 遮挡（Occlusion） 背景干扰（Background clutter） 类内差异（Intra-class variation）：同种物体年龄外表上有很大不同 面对以上所有变化及其组合，好的图像分类模型能够在面对上述挑战和干扰时具有很好的鲁棒性。 图像分类方法我们希望分类算法不是只适用于某个特定的种类，而是能够对所有种类的物体进行分类识别。 数据驱动的方法： 输入：输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为训练集 学习：使用输入的数据集训练分类器 评价：让分类器来预测新的图像的分类标签，并以此来评价分类器的质量 1. 最近邻算法（Nearest Neighbor分类器）训练：记录所有的数据和标签 预测：返回与输入图片最相近的样本数据的标签 在现实使用过程中，我们希望分类器的训练过程更长，而测试过程很快，但最近邻算法由于需要将测试图片与训练集里的所有样本进行比较，测试时间会很长，且预测效果不好。 2. K-近邻算法（K-Nearest Neighbors)在最近邻算法基础上做出一些改进，不只是寻找最近的1个点，而是找到最近的K个点，在这些点中进行投票，得到测试图片的标签。k值更大时，可以让分类的效果更平滑，使得分类器对于噪声更具有鲁棒性。 衡量两个图片的相似性方法，最简单的是计算两张图片像素矩阵的L1距离（曼哈顿距离）：$d_1(I_1,I_2)=\sum_P|I_1^P-I_2^p|$ L2距离（欧氏距离）：$d_2(I_1,I_2) = \sqrt{\sum_p(I_1^P-I_2^p)^2}$ 比较：L1距离取决于坐标系统的选择，当转动坐标轴时L1距离会发生变化，但L2距离不会。如果输入的特征向量对任务有重要的意义，则L1更合适，如果向量没有明确的含义，L2距离更加自然。 超参数:k的取值和距离的衡量方式选择都是超参数，超参数是无法在学习过程中得到的，而是要我们要给模型设置的。超参数的设置是依赖问题和数据的，所以一般要尝试不同的可能取值来检测哪种超参数的表现更好。 在设置超参数的过程中，不能在训练集或者测试集上寻找表现最好的超参数，而是应该将数据分为训练集，验证集和测试集，在训练集上运用不同的超参数来训练模型，在验证集上评估模型的效果，选择在验证集上效果最好的一组超参，再将这个模型运用在测试集上。对于小规模的数据集，还可以采用交叉验证方法：将测试集以外的数据分成K份，在其中（K-1)份上训练模型，在第K份数据上检验效果。 KNN算法在图像分类的问题中不会被用到，因为在预测数据时运算时间很长，L1和L2这种向量距离用在图像比较上不太合适，无法表示图像之间视觉感知的差异。另一个问题是维度灾难，KNN算法需要用训练数据将样本空间分成几个小的部分，若需要达到好的效果要求样本能够密集地分布在样本空间中，那么在高维数据中训练数据的数量就要是指数倍的增加，这是很难实现的。 3. 线性分类器线性分类方法是一种参数模型，通过训练数据学习出一组参数W用于预测新的样本，而非像KNN方法一样需要存储全部的训练数据，提高了测试的效率。在参数模型中，我们会获得一个包含输入数据x和参数W的函数$f(x,W)$,得到十个数字表示10个类别对应的分数。线性分类器中$f(x,W) = Wx+b$,b是偏差项，不与数据交互，只提供每个类别的偏好值。 线性分类模型可以理解为一种模板匹配方法，W矩阵中的每一行相当于每个图像类别学习出的模板。通过输入数据与模板的成绩得到图像的像素点与模板之间的相似之处，而偏差项给出了每个类的偏离量。因此线性分类器有每个类别只学习一个模板的限制。 线性分类器还可以在高维空间的角度来理解，每张图片代表着一个高维空间中的点，线性模型试图通过画出平面对不同类别的图像进行分割。 但线性模型的缺点是有很多形式的数据不能用线性平面进行分割。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CS231</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231课程笔记1--Introduction]]></title>
    <url>%2F2018%2F10%2F13%2FCS231%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[计算机视觉历史进展 CNN算法发展 计算机视觉历史进展目标分割：把一张图片的像素点归到有意义的区域 面部检测：使用Adaboost进行实时面部检测 目标检测：STFT特征，通过观察目标的某些部分和特征在变化中具有的表现性和不变性。所以目标识别的首要任务就是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配， 识别整幅图的场景：金字塔匹配：这个算法从图片的各个部分各像素抽取特征并把他们放在一起作为一个特征描述，然后使用特征描述跑SVM模型。 目标识别：标注数据集PASCAL Visual Object Challenge，Imagenet Imagenet竞赛中2012年CNN卷积神经网络模型取得了巨大的进步 CNN算法发展CNN算法在90年代被发明，但直到近几年才流行起来的原因 1.计算机运算能力的提升，GPU并行运算 2.数据集的完善，为训练网络提供了条件]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CS231</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这是我的第一篇博客]]></title>
    <url>%2F2018%2F10%2F12%2F%E6%96%B0%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[嘻嘻~这就是我的博客小窝啦]]></content>
      <tags>
        <tag>介绍</tag>
      </tags>
  </entry>
</search>
